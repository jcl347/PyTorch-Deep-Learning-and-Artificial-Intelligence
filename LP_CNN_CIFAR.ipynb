{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOgnbb/m8+IYBiI71r10jw4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcl347/PyTorch-Deep-Learning-and-Artificial-Intelligence/blob/main/LP_CNN_CIFAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KXpWuiWMUcOw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# examples: https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        "transformer_train = torchvision.transforms.Compose([\n",
        "  # torchvision.transforms.ColorJitter(\n",
        "  #     brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "  transforms.RandomCrop(32, padding=4),\n",
        "  torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
        "  # torchvision.transforms.RandomRotation(degrees=15),\n",
        "  torchvision.transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
        "  # torchvision.transforms.RandomPerspective(),\n",
        "  transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='.',\n",
        "    train=True,\n",
        "    transform=transformer_train,\n",
        "    download=True)\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='.',\n",
        "    train=False,\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=True)"
      ],
      "metadata": {
        "id": "O8Nv0N7nXD_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# behaves differently from MNIST / Fashion MNIST\n",
        "# it is a Numpy array!\n",
        "train_dataset.data"
      ],
      "metadata": {
        "id": "BIoTdvl0XFKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we are working with color images now\n",
        "train_dataset.data.shape"
      ],
      "metadata": {
        "id": "_bbBkzf7XHQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# behaves differently from MNIST / Fashion MNIST\n",
        "# it is a list!\n",
        "train_dataset.targets"
      ],
      "metadata": {
        "id": "mkmwElGCXI4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of classes\n",
        "K = len(set(train_dataset.targets))\n",
        "print(\"number of classes:\", K)"
      ],
      "metadata": {
        "id": "jfrg6KRHXLyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loader\n",
        "# Useful because it automatically generates batches in the training loop\n",
        "# and takes care of shuffling\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "iYlKV_b7XM3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make one for testing\n",
        "train_dataset_fixed = torchvision.datasets.CIFAR10(\n",
        "    root='.',\n",
        "    train=True,\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=True)\n",
        "train_loader_fixed = torch.utils.data.DataLoader(\n",
        "    dataset=train_dataset_fixed,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)"
      ],
      "metadata": {
        "id": "2NB5048uXN05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the data transformer mapped the data to (0, 1)\n",
        "# and also moved the color channel before height/width\n",
        "tmp_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=1,\n",
        "                                           shuffle=True)\n",
        "\n",
        "for x, y in tmp_loader:\n",
        "  print(x)\n",
        "  print(x.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "UR28Ez0aXOtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, K):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    # define the conv layers\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.MaxPool2d(2),\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.MaxPool2d(2),\n",
        "    )\n",
        "    self.conv3 = nn.Sequential(\n",
        "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.MaxPool2d(2),\n",
        "    )\n",
        "\n",
        "    # Useful: https://pytorch.org/docs/stable/nn.html#torch.nn.MaxPool2d\n",
        "    # H_out = H_in + 2p - 2 --> p = 1 if H_out = H_in\n",
        "\n",
        "    # Easy to calculate output\n",
        "    # 32 > 16 > 8 > 4\n",
        "\n",
        "    # define the linear layers\n",
        "    self.fc1 = nn.Linear(128 * 4 * 4, 1024)\n",
        "    self.fc2 = nn.Linear(1024, K)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = F.dropout(x, p=0.5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, p=0.2)\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "llOX4b6bXQPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "model = CNN(K)"
      ],
      "metadata": {
        "id": "S8PDzaw5XRRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "WyG-uHWTXSEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "kcsQrW-pXTBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A function to encapsulate the training loop\n",
        "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
        "  train_losses = np.zeros(epochs)\n",
        "  test_losses = np.zeros(epochs)\n",
        "\n",
        "  for it in range(epochs):\n",
        "    model.train()\n",
        "    t0 = datetime.now()\n",
        "    train_loss = []\n",
        "    for inputs, targets in train_loader:\n",
        "      # move data to GPU\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "      # print(\"inputs.shape:\", inputs.shape)\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward pass\n",
        "      # print(\"about to get model output\")\n",
        "      outputs = model(inputs)\n",
        "      # print(\"done getting model output\")\n",
        "      # print(\"outputs.shape:\", outputs.shape, \"targets.shape:\", targets.shape)\n",
        "      loss = criterion(outputs, targets)\n",
        "\n",
        "      # Backward and optimize\n",
        "      # print(\"about to optimize\")\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss.append(loss.item())\n",
        "\n",
        "    # Get train loss and test loss\n",
        "    train_loss = np.mean(train_loss) # a little misleading\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = []\n",
        "    for inputs, targets in test_loader:\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, targets)\n",
        "      test_loss.append(loss.item())\n",
        "    test_loss = np.mean(test_loss)\n",
        "\n",
        "    # Save losses\n",
        "    train_losses[it] = train_loss\n",
        "    test_losses[it] = test_loss\n",
        "\n",
        "    dt = datetime.now() - t0\n",
        "    print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
        "      Test Loss: {test_loss:.4f}, Duration: {dt}')\n",
        "\n",
        "  return train_losses, test_losses"
      ],
      "metadata": {
        "id": "4MWEx2taXUSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, test_losses = batch_gd(\n",
        "    model, criterion, optimizer, train_loader, test_loader, epochs=80)"
      ],
      "metadata": {
        "id": "SGMa6ppvXVQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the train loss and test loss per iteration\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(test_losses, label='test loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K5OZBlZhXW2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "\n",
        "model.eval()\n",
        "n_correct = 0.\n",
        "n_total = 0.\n",
        "for inputs, targets in train_loader_fixed:\n",
        "  # Move to GPU\n",
        "  inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "  # Forward pass\n",
        "  outputs = model(inputs)\n",
        "\n",
        "  # Get prediction\n",
        "  # torch.max returns both max and argmax\n",
        "  _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "  # update counts\n",
        "  n_correct += (predictions == targets).sum().item()\n",
        "  n_total += targets.shape[0]\n",
        "\n",
        "train_acc = n_correct / n_total\n",
        "\n",
        "\n",
        "n_correct = 0.\n",
        "n_total = 0.\n",
        "for inputs, targets in test_loader:\n",
        "  # Move to GPU\n",
        "  inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "  # Forward pass\n",
        "  outputs = model(inputs)\n",
        "\n",
        "  # Get prediction\n",
        "  # torch.max returns both max and argmax\n",
        "  _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "  # update counts\n",
        "  n_correct += (predictions == targets).sum().item()\n",
        "  n_total += targets.shape[0]\n",
        "\n",
        "test_acc = n_correct / n_total\n",
        "print(f\"Train acc: {train_acc:.4f}, Test acc: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "S9shn_J3XX1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "  \"\"\"\n",
        "  This function prints and plots the confusion matrix.\n",
        "  Normalization can be applied by setting `normalize=True`.\n",
        "  \"\"\"\n",
        "  if normalize:\n",
        "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "      print(\"Normalized confusion matrix\")\n",
        "  else:\n",
        "      print('Confusion matrix, without normalization')\n",
        "\n",
        "  print(cm)\n",
        "\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "\n",
        "  fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(j, i, format(cm[i, j], fmt),\n",
        "               horizontalalignment=\"center\",\n",
        "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "LziiJSekXZDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get all predictions in an array and plot confusion matrix\n",
        "\n",
        "x_test = test_dataset.data\n",
        "y_test = np.array(test_dataset.targets)\n",
        "p_test = np.array([])\n",
        "for inputs, targets in test_loader:\n",
        "  # Move to GPU\n",
        "  inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "  # Forward pass\n",
        "  outputs = model(inputs)\n",
        "\n",
        "  # Get prediction\n",
        "  _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "  # update p_test\n",
        "  p_test = np.concatenate((p_test, predictions.cpu().numpy()))\n",
        "\n",
        "cm = confusion_matrix(y_test, p_test)\n",
        "plot_confusion_matrix(cm, list(range(10)))"
      ],
      "metadata": {
        "id": "pIf8jF99XaFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label mapping\n",
        "labels = '''airplane\n",
        "automobile\n",
        "bird\n",
        "cat\n",
        "deer\n",
        "dog\n",
        "frog\n",
        "horse\n",
        "ship\n",
        "truck'''.split()"
      ],
      "metadata": {
        "id": "ggwuHWBOXa-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show some misclassified examples\n",
        "p_test = p_test.astype(np.uint8)\n",
        "misclassified_idx = np.where(p_test != y_test)[0]\n",
        "sample_idx = np.random.choice(misclassified_idx, 10, replace=False)\n",
        "plt.figure(figsize=(32,32))\n",
        "for j, i in enumerate(sample_idx):\n",
        "  plt.subplot(10, 1, j + 1)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(x_test[i].reshape(32,32,3))\n",
        "  plt.title(\"True label: %s Predicted: %s\" % (labels[y_test[i]], labels[p_test[i]]));"
      ],
      "metadata": {
        "id": "-44Pf5feXcC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "id": "-wXHxHrqXeGG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}